----


vision landing 예시
 - https://github.com/szebedy/autonomous-drone/
 - https://github.com/goodrobots/vision_landing/
 - https://github.com/claymation/lander/

ROS와 비콘으로 crazyflies 여러대 날리는 문서
 - http://act.usc.edu/publications/Hoenig_Springer_ROS2017.pdf
 - http://act.usc.edu/publications/Preiss_ICRA2017.pdf
 - https://github.com/USC-ACTLab/crazyswarm
 - https://www.youtube.com/watch?v=D0CrjoYDt9w
 - https://crazyswarm.readthedocs.io/en/latest/hardware.html#large-quadrotor
 - https://github.com/whoenig/libMultiRobotPlanning

ros blob detection https://www.youtube.com/watch?v=a6XvL7NVeTk
https://www.robotigniteacademy.com/en/course/ros-perception-in-5-days_5_0/
----

4. aruco

aruco: library for detect marker

뭘할수 있나?
 1. detect marker
 2. calibrate camera  (위치 estimation할때 필수)

marker
 - binary code (dictionary)
 - 위치. 방향을 알 수 있다.

download
 - https://sourceforge.net/projects/aruco/

# aruco build

mkdir build
cd build
cmake ..
make
make install

# simple detecter build

위치 /home/donghee/Dropbox/dev/CodingLife/20180724/PX4-Dev-Workshop/opencv/aruco/aruco_testproject

mkdir aruco_testproject

cat CMakeLists.txt

cmake_minimum_required(VERSION 2.8)
project(aruco_testproject)
find_package(aruco REQUIRED )
add_executable(aruco_simple aruco_simple.cpp)
target_link_libraries(aruco_simple  aruco)

cat aruco_simple.cpp

#include <iostream>
#include <aruco/aruco.h>
#include <opencv2/highgui.hpp>
int main(int argc,char **argv)
{
  try
  {
      if (argc!=2) throw std::runtime_error("Usage: inimage");
      aruco::MarkerDetector MDetector;
      //read the input image
      cv::Mat InImage=cv::imread(argv[1]);
    //Ok, let's detect
      MDetector.setDictionary("ARUCO_MIP_36h12");
      //detect markers and for each one, draw info and its boundaries in the image
      for(auto m:MDetector.detect(InImage)){
          std::cout<<m<<std::endl;
          m.draw(InImage);
      }
      cv::imshow("in",InImage);
      cv::waitKey(0);//wait for key to be pressed
  } catch (std::exception &ex)
  {
      std::cout<<"Exception :"<<ex.what()<<std::endl;
  }
}


mkdir build
cd build
cmake .. -Daruco_DIR=../../aruco-3.0.12 -DOpenCV_DIR=<path2OpenCVConfig.cmake>
make
./aruco_simple image_withmarkers.jpg


1 read the input image
2. marker dector
3. detect! and return vector
4. print vector (id)
5. draw marked image
6. create window
7. show image

참고:
 - ArUco Library Documentation https://docs.google.com/document/d/1QU9KoBtjSM2kF6ITOjQ76xqL7H0TEtXriJX5kwi9Kgc/edit
 - https://bitbucket.org/NiklasGeorg/markerdetection



<2018-11-07 Wed>
 - 최근 버전에 precland 모드에서 MAVLINK_MSG_ID_LANDING_TARGET
받는게 추가 되었다. handle_message_landing_target
mavros 에서 LANDING TARGET 플러그인을 추가해야겠다.
https://github.com/mavlink/mavros/tree/master/mavros_extras/src/plugins

 - CopterExpress의 clever 프로젝트

offboard mode 사용 간단하게 할 수 있는 서비스 추가 되어 있음 get_telemetry, navigate
https://github.com/CopterExpress/clever/blob/master/clever/src/simple_offboard.py

/mavros/setpoint_raw/local raw노드는 뭐지? 메시지가 다르군.

세종대 마커 이용해서 정밀 랜딩
navigation using  aruco marker
https://github.com/CopterExpress/clever/blob/master/docs/aruco.md

1. aruco 로 마커인식
2. aruco 로 위치 인식  https://github.com/CopterExpress/clever/tree/master/aruco_pose/src
3. aruco tf 보내기 (aruco_map)
4. local origin, aruco_map_vision, 던지기. fcu_horiz https://github.com/CopterExpress/clever/blob/0629bd718cc549db11fae7ed2acb672333ced50b/clever/src/aruco_vpe.cpp
5. vision_position_pub_ 던지기.
6. simple offboard api 작성
7. aruco tf 받아서 offboard api 작성
8. spiral 돌기 만들기 https://youtu.be/aqBION3TVhg?t=43

관련 튜토리얼
https://clever.copterexpress.com/aruco.html


----

발표자료
https://elinux.org/images/7/79/Flying_Penguins-_Embedded_Linux_Applications_for_Autonomous_UAVs.pdf

precision landing 예시
http://github.com/claymation/lander

1. SEEKING -> LANDING
2. LANDING -> LANDED
3. LANDED

precision landing 참고
 - https://github.com/goodrobots/vision_landing
 - https://github.com/claymation/lander/blob/master/src/py/lander/nodes/commander.py
 - https://github.com/yankailab/OpenKAI/blob/master/kiss/app/apCopter_aruco.kiss
 - https://github.com/yankailab/OpenKAI/tree/master/kiss/app
 - https://diydrones.com/profiles/blogs/precision-landing-with-opencv-and-aruco-markers-part-1
 - https://www.youtube.com/watch?v=IJlt8dE_s5k
 - https://github.com/openmv/openmv/tree/master/scripts/examples/18-MAVLink
precision landing 키는건 rc input읽어서 하면 되겟네

https://github.com/PX4/Firmware/blob/master/src/modules/landing_target_estimator/KalmanFilter.cpp

"mavros/rc/in"

#+BEGIN_SRC
import rospy
import mavros_msgs

# see ROS tutorials! init required
rospy.init_node("rcin_sub")

sub = rospy.Subscriber("mavros/rc/in", mavros_msgs.RCIn, lambda msg: print(msg))

rospy.spin()
#+END_SRC

keyboard 입력

#+BEGIN_SRC
#include <termios.h>

int getch()
{
  static struct termios oldt, newt;
  tcgetattr( STDIN_FILENO, &oldt);           // save old settings
  newt = oldt;
  newt.c_lflag &= ~(ICANON);                 // disable buffering
  tcsetattr( STDIN_FILENO, TCSANOW, &newt);  // apply new settings

  int c = getchar();  // read character (non-blocking)

  tcsetattr( STDIN_FILENO, TCSANOW, &oldt);  // restore old settings
  return c;
}

while (ros::ok())
{
  int c = getch();   // call your non-blocking input function
  if (c == 'a')
      printf("forward\n");
  else if (c == 'd')
      printf("backward\n");
}
#+END_SRC
